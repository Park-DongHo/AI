{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1주차과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkExYf5dTr9Xjn0heGKOei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Park-DongHo/AI/blob/master/1%EC%A3%BC%EC%B0%A8%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4VQZqEsW08D",
        "colab_type": "text"
      },
      "source": [
        "#1주차 과제\n",
        "* 인공지능 사례 분석\n",
        "* 글쓴이 : 박동호 (ehdgh4875@naver.com)\n",
        "- - - \n",
        "##1. 언어\n",
        "###1.1 개요\n",
        "* 마이크로소프트(이하, MS)는 지난해 11월, 처음으로 인공지능 신경망(ANN, Artificial Neural Network) 기반 번역 서비스를 공개했습니다. 인공 신경망은 인간의 두뇌와 비슷한 방식으로 여러 가지 정보를 처리하는 알고리즘을 말하는데요. 당시 MS는 영어, 독일어, 아랍어, 중국어를 포함한 10가지 언어를 지원했고, 이번에 한국어를 추가하면서 총 11가지 언어에 최대 10,000자까지 번역하게 됐습니다.\n",
        "\n",
        "###1.2 원리\n",
        "* 인공지능 기반의 제품은 서비스를 개발하고 운영하기 위해서 다음과 같은 것들이 필요 합니다.\n",
        "무엇보다 학습 교재로 쓸 __데이터를 확보__하여야 합니다. 방대한 양이 필요함은 물론이고 다양성 또한 중요합니다. 또한 기계가 이해하고 학습할 수 있도록 __‘데이터 가공’__ 과정도 필요합니다. 여기에 사물 판별, 감정 분석, 태그 생성 등 알맞은 메타 데이터를 부여하는 __‘데이터 어노테이션'__ 과정을 거쳐야 비로소 기계 학습형 데이터가 되는 것이죠.\n",
        "\n",
        "* 데이터가 많을수록, 다양할수록 데이터의 정확도를 높일 수 있습니다. 신조어, 구어, 일상생활에서의 표현 등 새롭고 다양하며 정확한 데이터는 인공지능 번역기가 ‘진짜’ 사람처럼 유행에 맞게 언어를 구사할 수 있도록 도와줍니다.\n",
        "\n",
        "###1.3 제품사례 - 플리토\n",
        "* 번역 서비스 ‘플리토’에서는 ‘인공지능 번역 서비스’를 제공하고 있는데요. 번역기를 예로 다시 한번 보자면, 인공지능 번역기는 인간의 언어 능력을 모방하여 만들어진 기계입니다. 각 언어마다 단어, 문장 구조, 문법 등 충분한 언어 데이터와 알고리즘을 토대로 인공지능을 반복적으로 학습시켜 만들어진 것이죠. 인공지능 번역기에 학습된 데이터 양이 많을수록 그리고 다양할수록, 번역의 품질은 높아지고 더욱 자연스러운 번역 결과를 제공합니다.\n",
        "\n",
        "* 예를 들어, ‘좋다’라는 한국어를 상황에 따라 영어로는 ‘good’, ‘nice’, ‘like’ 등으로 다르게 표현하고, ‘갑분싸(갑자기 분위기 싸해짐)’라는 신조어를 이해해 영어로 ‘the atmosphere suddenly became uncomfortable’라고 표현합니다.\n",
        "\n",
        "![1-1](1-1.png)\n",
        "\n",
        "  출처 : [모바일인사이드](https://www.mobiinside.co.kr/2020/03/16/flitto-data/), [이롭게닷컴](https://iropke.com/archive/artificial-translator.html), [이미지출처 : 네이버블로그](https://m.blog.naver.com/PostView.nhn?blogId=hlchoir&logNo=221283520213&proxyReferer=https:%2F%2Fwww.google.com%2F)\n",
        "- - -\n",
        "##2. 음성\n",
        "###2.1 개요\n",
        "* 인공지능 제품이나 서비스를 떠올릴 때, 너무 당연하다고 인식되는 기능이 있죠. 바로 ‘음성인식’입니다. 스마트폰의 음성 기반 인공지능 비서는 이름만 불러도 기다렸다는 듯 인사를 건넵니다. 차 안에 한 대씩은 있는 자동차 내비게이션은 물론 인공지능 스피커도 최근에는 흔히 볼 수 있게 되었죠. 덕분에 말 한마디를 건네서 날씨나 지리 정보를 쉽게 얻을 수 있고 기계와 농담까지 주고받을 수 있게 되었습니다.\n",
        "\n",
        "###2.2 원리\n",
        "* 우리가 인공지능 기반 음성인식 제품에 말을 하면, “음성 입력 및 인식 → 자연어 처리 → 인식 결과”의 단계를 거칩니다. 기계가 사람의 언어를 인식하고 이해하기 위해 필요한 과정이죠.\n",
        "1. 첫 번째 과정에서는 음성 입력 과정을 거쳐 사람의 음성을 컴퓨터가 이해할 수 있도록 텍스트화합니다.\n",
        "이 기술을 STT(Speech To Text)라고 하는데요. 어린아이가 받아쓰기를 하듯이 사람의 음성을 텍스트로 옮기는 것입니다. 주변 소음을 제외한 말소리를 파악하고 이어서 각 발음과 단어를 인식한 후 핵심어와 연결 단어를 인식해 입력해야 하므로 생각보다 간단하고 쉽지만은 않습니다.\n",
        "\n",
        "2. 두 번째는 자연어 처리(Natural Language Processing, NLP) 과정입니다. 자연어란 사람이 의사소통을 위해 사용하는 언어입니다. 자연어 처리란 컴퓨터가 자연어를 분석하여 이해하고 처리하는 기술이죠.\n",
        "이 과정에서는 자연어에 대한 형태소 분석, 구문 해석, 의미 분석, 화용 분석 등을 통해 컴퓨터가 문장에 담긴 의도를 파악하게 합니다. 이 자연어 처리는 인공지능의 주요 분야입니다. 인공지능 기계가 사람의 언어를 얼마나 잘 파악하였는지를 알 수 있는 과정이죠.\n",
        "\n",
        "3. 앞선 과정을 거쳐 마지막으로 기계는 인식 결과를 내놓습니다. 인식된 요청에 따라 가장 최적의 결과를 찾아내고, TTS(Text to Speech) 기술을 통해 사람의 말소리처럼 응답하는 것이죠. 친구에게 메시지를 보내라고 말했다면 전달한 내용으로 메시지를 전송하고, 날씨를 물어봤다면 인터넷에서 위치 기반의 날씨를 검색해 대답해줍니다.\n",
        "\n",
        "###2.3 제품사례 - 에코\n",
        "* 아마존닷컴이 개발한 스마트 스피커입니다. 이 장치는 \"알렉사\"(Alexa)라는 이름에 반응하는 음성 통제 가상 비서 서비스 알렉사에 연결됩니다. 깨우는 낱말(wake word)은 사용자에 의해 \"아마존\", \"에코\", \"컴퓨터\"로 변경이 가능하다. 이 장치는 음성 상호작용, 음악 재생, 할 일 목록 만들기, 알람 설정, 스트리밍 팟캐스트, 오디오북 재생, 날씨, 트래픽 및 기타 실시간 정보 제공을 할 수 있습니다. 또한 스마트 홈 허브 역할을 하면서 자신이 직접 여러 스마트 장치를 통제할 수 있습니다.\n",
        "\n",
        "* 인간의 목소리(이하, 명령)가 AI 스피커의 마이크를 통해 입력되면 ‘스피치 프로세서(SPEECH PROCESSOR)’는 음성 신호를 음성 신호 벡터로 변화시킵니다. 음성 신호 벡터는 ‘스피치 인식기(SPEECH RECOGNIZER)’와 ‘언어 특징 추출기(LINGUISTIC FEATURE EXTRACTOR)’를 통해 ‘언어 표현 정보(LINGUISTIC REPRESENTATION)’로 추출됩니다. 여기서 언어 표현 정보는 기존의 단어 관련 정보를 고려하여 추출됩니다.\n",
        "\n",
        "* 알렉사가 입력된 언어를 제대로 이해하기 위해서는 스킬, 의도, 슬롯에 대한 정확한 분석이 선행돼야 합니다. 때문에 알렉사의 의도 분류기는 입력된 데이터를 기반으로 학습이 가능합니다. ‘인공 뉴럴 네트워크(Artificial Neural Network)’와 ‘딥 뉴럴 네트워크(Deep Neural Network)’를 사용할 수 있는 의도 분류기는 축적되는 데이터에 따라 뉴럴 네트워크의 변화하는 가중치를 감지하고, 이를 학습해 보다 정확하게 명령의 의도를 판단할 수 있게 됩니다.\n",
        "\n",
        "![2-1](2-1.png)\n",
        "\n",
        "  출처 : [clomag](http://clomag.co.kr/article/3103), [mobiinside](https://www.mobiinside.co.kr/2020/04/28/flitto-ai/), [이미지출처 : bloter.net](http://www.bloter.net/archives/253067)\n",
        "- - -\n",
        "##3. 이미지\n",
        "###3.1 개요\n",
        "* ‘이미지 인식(Image recognition)’, 머신러닝과 인공지능(AI)을 포함한 기술 산업 전반을 뜨겁게 달구고 있는 주요 이슈입니다. 특히 컴퓨터 비전, 즉 영상 처리 기술은 무인 자동차, 얼굴 인식, 의료 결과 예측 등 수많은 혁신 기술들을 현실화하는 핵심 요소입니다.\n",
        "* 분류 작업을 위해서는 가장 단순한 모델을 선택하는 것이 현명합니다. 모델이 단순할수록 더욱 안정적이며, 비즈니스 이해관계자들에게 설명하기도 훨씬 쉽기 때문인데요. 그렇지만 일반적으로 이미지 인식은 이미지 정보의 복잡성 때문에 훨씬 복잡한 모델을 필요로 합니다.\n",
        "\n",
        "###3.2 원리\n",
        "* 이미지를 여러 패턴으로 분류해서, 패턴형 데이터를 학습하여 새로운 이미지가 주어질 때 이것이 무엇인지 정확하게 알아내는 원리입니다. 주로 딥러닝 혹은 신경망네트워크가 이 기능을 구현하는 데 쓰입니다.\n",
        "\n",
        "* 지문을 예로 들면 사람마다 지문 모양이 다르기 때문에 각 지문으로 패턴을 만든 후 여러 지문 데이터를 학습하면서 통계학적 패턴을 구분하고, 지문 확인이 필요할 때 어떤 패턴에 해당되는지를 계속적으로 추적해서 최종적으로 지문의 주인을 가려냅니다. 학습량이 늘어날수록 판별의 정확도는 올라갑니다.\n",
        "\n",
        "###3.3 제품사례 - 구글렌즈\n",
        "* 구글 렌즈는 현재 일부 기기에는 카메라 앱에 통합된 상태며 별도의 앱이나 구글 포토, 구글 어시스턴트에도 포함돼 있습니다. 기본 기술은 비전 AI와 구글의 지식 그래프(Knowledge Graph)입니다. 지식 그래프는 시맨틱 검색 정보를 사용해 검색결과를 향상시키는 기술이며 구글의 여러 검색에 적용된 지식 베이스입니다. 비전 AI의 경우 몇천장의 이미지를 시작으로 이미지의 각 각도에 따라 같은 사물임을 인지해야 하므로 수조 개 단위로 확장된 상태입니다. 최근 정확도가 개선된 것은 머신 러닝의 결과입니다.\n",
        "\n",
        "* 구글 렌즈의 핵심 기능으로 자동차와 마찬가지로 사물의 벡터값을 만들어내고 패턴을 파악해 옷, 신발, 구두 등 비슷한 제품을 찾아주는 기능있습니다. 구글 검색이 가능한 쇼핑몰로 직접 연결됩니다.\n",
        "\n",
        "* 메뉴를 번역하고 랜드마크, 상점 등을 파악하는 등에도 쓰입니다. 이것을 분석할 때는 다양한 구글의 소스를 함께 끌어와서 씁니다. 구글 스트리트뷰 내 이미지, 간판의 텍스트 등을 확보해두었다가 사용자가 구글 렌즈로 찍으면 빠르게 비교하는 것입니다. 동물의 얼굴도 비슷한 방법으로 비교합니다. 특이한 메뉴를 번역하거나, 기프트 카드나 와이파이 비밀번호 등 키보드로 입력하기 어려운 난수를 복사하는 데 유용합니다.\n",
        "\n",
        "![3-1](3-1.gif)\n",
        "\n",
        "출처 : [AI타임스](http://www.aitimes.com), [SAS](https://www.sas.com/ko_kr/solutions/ai-mic/blog/image-recognition.html),\n",
        "  [bylineNetwork](https://byline.network/2018/06/28-22/), [이미지 출처 : bylineNetwork](https://byline.network/wp-content/uploads/2018/05/lens_clothing_inPhone.gif)\n",
        "\n",
        "- - -\n",
        "##4. 자율주행\n",
        "###4.1 개요\n",
        "* 자율주행자동차란 운전자의 개입 없이 주변 환경을 인식하고, 주행 상황을 판단하여 차량을 제어함으로써 스스로 주어진 목적지까지 주행하는 자동차 를 말합니다.\n",
        "\n",
        "###4.2 원리\n",
        "* 자율주행자동차의 기본적인 작동은 사람이 운전하는 원리와 같이 ‘인지-판단-제어’의 3단계를 거칩니다. 먼저 최종목적지를 입력하고 경로를 결정합니다. 이후 차량에 장착된 센서들과 외부 통신을 통해 주변 상황에 대한 정보를 수집합니다. 그다음부터는 정밀하게 위치를 계산하고, 조향 및 가·감속을 결정해 차량이 스스로 경로를 따라 운행하게 됩니다.\n",
        "* 이러한 작동 원리를 구현하는 방식에는 크게 차량의 자율성과 협조운전이라는 두 가지 방식으로 나뉩니다. 차량의 자율성이 차량 자체의 자율주행에 중점을 둔 ADAS(Advanced Driver Assistance Systems) 의존적인 방식이라면, 협조운전은 ICT 통신을 활용하여 외부와의 협조에 중점을 둔 V2X(Vehicle to Everything) 의존적인 방식입니다. 자율주행자동차는 이 두 가지 방식이 합쳐지는 것으로 구현됩니다.\n",
        "\n",
        "###4.3 제품사례 - 테슬라\n",
        "* 테슬라 오토파일럿은 테스라모터스가 전기 자동차 모델S에 자동 운전 모드 소프트웨어를 추가하여 만든 자동주행시스템을 말합니다.\n",
        "자동 운전 차량으로 사람이 운전하지 않고 차량이 자동 운전하는 것이며, 미래에는 자동운전 차량이 일반화되어 핸들을 잡는 것이 허용되지 않을 것으로 예측됩니다.\n",
        "\n",
        "* 테슬라(Tesla)는 미국의 전기자동차 업체이고, 오토파일럿(Autopilot)은 테슬라의 전기차 ‘모델S’에 장착된 자율주행 소프트웨어를 말합니다. 오토파일럿(Autopilot)의 원래 뜻은 항공기의 ‘자동항법장치’를 의미합니다. 테슬라는 이런 의미를 자사의 소프트웨어 이름으로 붙인 것이지요. 완전한 자동운전이 가능한 항공기와 달리, 자동차는 아직 ‘부분적 자율주행’만이 가능합니다.\n",
        "\n",
        "* 테슬라의 ‘오토파일럿’ 소프트웨어는 인터넷을 통한 업그레이드 서비스를 지속적으로 받을 수 있다는 게 가장 큰 특징입니다. 오토파일럿을 장착한 전기차 ‘모델S’에는 주위 상황을 파악할 수 있는 장거리 초음파 센서가 12개 장착되어 있습니다. 이 외에도 카메라, 레이더, 제어 브레이크 등이 탑재되어 차량 컨트롤을 모두 자동으로 수행할 수 있도록 설계되어 있습니다.\n",
        "\n",
        "![4-1](4-1.jpg)\n",
        "\n",
        "  출처 : [FESCARO](https://www.fescaro.com/ko/archives/609), [NDSL](http://www.ndsl.kr/ndsl/issueNdsl/detail.do?techSq=59), 이미지출처 : 현대자동차 공식 블로그"
      ]
    }
  ]
}
